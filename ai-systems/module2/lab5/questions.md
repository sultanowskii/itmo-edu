# Вопросы

## Переобучение / недообучение

Переобучение (overfitting) — негативное явление, возникающее, когда алгоритм обучения вырабатывает предсказания, которые слишком близко или точно соответствуют конкретному набору данных и поэтому не подходят для применения алгоритма к дополнительным данным или будущим наблюдениям.

Недообучение (underfitting) — негативное явление, при котором алгоритм обучения не обеспечивает достаточно малой величины средней ошибки на обучающей выборке. Недообучение возникает при использовании недостаточно сложных моделей.

## Критерий остановки построения дерева

Правило остановки

- при небольшой выборке дерево строят до ее исчерпания
- при большой – применяют отсечение
- минимально допустимое число примеров
- макс.глубина дерева
- остановка по критерию (процент верно определенных примеров)

**Отсечение**: идем от листов к корню, помечая по некоторому критерию, например качество классификации, узлы на удаление. Вместо узлов ставится лист с меткой класса с наибольшим количеством исходов в этом поддереве.

## ROC снизу

Означает, что дерево отрабатывает хуже, чем рандом.

## Несбалансированный датасет

Несбалансированный датасет – набор данных, где количество примеров разных классов в данных существенно отличается.
